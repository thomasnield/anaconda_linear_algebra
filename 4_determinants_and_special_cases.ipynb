{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64764f12",
   "metadata": {},
   "source": [
    "# Determinants and Special Cases\n",
    "\n",
    "Now that we have some familiarity with transformations, let's do some analysis on these transformations that will be pertinent later. One of the most fundamental operations to assess a transformation is the determinant which we will cover first. Then we will talk about linear dependence and special cases we will see in matrix shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3ff90c",
   "metadata": {},
   "source": [
    "## The Determinant \n",
    "\n",
    "Take a look at this linear transformation below. We will also put an orange square with an area of $ 1 $ on the space. What happens to the area of the square during the transformation? \n",
    "<br><br><br>\n",
    "\n",
    "<video src=\"https://github.com/thomasnield/anaconda_linear_algebra/raw/main/media/01_DeterminantScene.mp4\" controls=\"controls\" style=\"max-width: 730px;\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d5f597",
   "metadata": {},
   "source": [
    "If you were able to notice the area increased with the transformation, you are on the right track. Even better, how much did it increase or decrease? In this case, we can clearly see that the area of the square increased by a factor of 6. This increase/decrease factor in a sampled area of a transformation is what we call the **determinant**. It shows how much a matrix increases or decreases the quantity of something. \n",
    "\n",
    "We can calculate the determinant using the NumPy `det()` function from its `linalg` package. Sure enough, we see the determinant is `6.0` for this given matrix $ \\begin{bmatrix} 3 & 0 \\\\ 0 & 2 \\end{bmatrix} $. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0196938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from numpy.linalg import det \n",
    "\n",
    "i_hat = np.array([3,0])\n",
    "j_hat = np.array([0,2])\n",
    "\n",
    "A = np.array([i_hat,j_hat]).transpose()\n",
    "\n",
    "det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a634ecb0",
   "metadata": {},
   "source": [
    "For a 2x2 matrix, you can calculate the determinant by hand by multiplying and adding the diagonal elemenets together. \n",
    "\n",
    "$\n",
    " det(\\begin{bmatrix} 3 & 0 \\\\ 0 & 2 \\end{bmatrix}) = (3)(2) + (0)(0) = 6 \n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6537ff",
   "metadata": {},
   "source": [
    "Here is another example with a shear transformation. What happens to the area and what do you think the determinant is? <br><br><br>\n",
    "\n",
    "<video src=\"https://github.com/thomasnield/anaconda_linear_algebra/raw/main/media/02_DeterminantSheerScene.mp4\" controls=\"controls\" style=\"max-width: 730px;\">\n",
    "</video>\n",
    "\n",
    "Knowing that an area for a rhombus shape is almost the same as a rectangle (base * height) should allow you to visually calculate the determinant as $ 2 $. Provided the exact matrix or $ \\hat{i} $ and $ \\hat{j} $, we can find indeed this is $ 2 $. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36a0250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from numpy.linalg import det \n",
    "\n",
    "i_hat = np.array([1,0])\n",
    "j_hat = np.array([0,2])\n",
    "\n",
    "A = np.array([i_hat,j_hat]).transpose()\n",
    "\n",
    "det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02c22d1",
   "metadata": {},
   "source": [
    "Negative determinants can exist as well. This happens when the orientation of the space flips somehow, and  $\\hat{i}$ and $\\hat{j} swap their clockwise positions. \n",
    "\n",
    "The matrix $ \\begin{bmatrix}0 & 1\\\\2 & 1\\end{bmatrix}  $ below has a determinant of $ -2 $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29995c87",
   "metadata": {},
   "source": [
    "\n",
    "<video src=\"https://github.com/thomasnield/anaconda_linear_algebra/raw/main/media/03_DeterminantInversionScene.mp4\" controls=\"controls\" style=\"max-width: 730px;\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13b1638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from numpy.linalg import det \n",
    "\n",
    "i_hat = np.array([0,2])\n",
    "j_hat = np.array([1,1])\n",
    "\n",
    "A = np.array([i_hat,j_hat]).transpose()\n",
    "\n",
    "det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7edbe63",
   "metadata": {},
   "source": [
    "Determinants also work in higher dimensions. Just think in terms of volume rather than area. Below, we have a cube of volume 1. After applying this transformation, we get a determinant of 4.5 as the cube increases in volume by that factor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c74e11",
   "metadata": {},
   "source": [
    "$\n",
    "A = \\begin{bmatrix} 1.5 & -1.2 & 2.5\\\\0 & 2.0 & 1.0\\\\0 & 0 & 1.5 \\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\n",
    "det(a) = 4.5\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1baae16",
   "metadata": {},
   "source": [
    "\n",
    "<video src=\"https://github.com/thomasnield/anaconda_linear_algebra/raw/main/media/04_ThreeDDeterminantScene.mp4\" controls=\"controls\" style=\"max-width: 730px;\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0821533b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from numpy.linalg import det \n",
    "\n",
    "i_hat = np.array([1.5,0,0])\n",
    "j_hat = np.array([-1.2,2,0])\n",
    "k_hat = np.array([2.5,1, 1.5])\n",
    "\n",
    "A = np.array([i_hat,j_hat,k_hat]).transpose()\n",
    "det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d3cfcd",
   "metadata": {},
   "source": [
    "## Linear Dependence "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f062e74f",
   "metadata": {},
   "source": [
    "Let's take this matrix $ A $ and then animate its transformation. What happens to the determinant? \n",
    "\n",
    "$ \n",
    "A = \\begin{bmatrix} -2 & 2 \\\\ 1 & -1 \\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccdcbb1",
   "metadata": {},
   "source": [
    "\n",
    "<video src=\"https://github.com/thomasnield/anaconda_linear_algebra/raw/main/media/05_ZeroDeterminantScene.mp4\" controls=\"controls\" style=\"max-width: 730px;\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1bcf23",
   "metadata": {},
   "source": [
    "Did you see that? Run the Python code below to calculate the determinant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fdeacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from numpy.linalg import det \n",
    "\n",
    "i_hat = np.array([-2,1])\n",
    "j_hat = np.array([2,-1])\n",
    "\n",
    "A = np.array([i_hat,j_hat]).transpose()\n",
    "\n",
    "det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b5bf9b",
   "metadata": {},
   "source": [
    "As you can see in the animation and Python code above, the determinant went to $ 0 $! This is an important concept because when a determinant goes to $ 0 $, it means there might be issues with the matrix for certain types of problems. For example, when we learn to solve systems of equations, a determinant of $ 0 $ means the systems of equations is unsolvable! \n",
    "\n",
    "What is something else you noticed? You might have noticed the basis vectors fell onto the same underlying line, and share the same direction (with negative scalars, of course). We also saw all of the 2D space compressed into a 1D space. \n",
    "\n",
    "Now let's consider a 3D matrix. What does a zero deteriminant look like? \n",
    "\n",
    "<video src=\"https://github.com/thomasnield/anaconda_linear_algebra/raw/main/media/06_ThreeDZeroDeterminantScene.mp4\" controls=\"controls\" style=\"max-width: 730px;\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913fd5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 0, 0], [-1, 1, 0], [1, 0, 0]])\n",
    "\n",
    "# Calculate the determinant of the matrix.\n",
    "determinant = np.linalg.det(A)\n",
    "\n",
    "# Print the determinant.\n",
    "print(determinant)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771cfd2b",
   "metadata": {},
   "source": [
    "Again, you can see this theme of a zero determinant reflecting a compression into lesser dimensions. This reflects a matrix that is linear dependent. \n",
    "\n",
    "> You might hear the term **rank** in linear algebra, which describes how many dimensions the matrix transforms into. If a 3D matrix compresses space into a line, it has a rank 1. If it compresses space into a plane, it has rank 2. If it stays in 3 dimensions, it has a rank of 3 and would be \"full rank\" because it maintains those dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa913302",
   "metadata": {},
   "source": [
    "## Special Case Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe8b275",
   "metadata": {},
   "source": [
    "Here is zoo of different types of matrices that are notable. \n",
    "\n",
    "### Square Matrix\n",
    "\n",
    "A square matrix is primarily what we have been working with. It has an equal number of rows and columns, and are used to describe vanilla linear transformations that stay on the same number of dimensions. Square matrices are a requirement for many operations like eigendecomposition. \n",
    "\n",
    "Below is a 3x3 square matrix. \n",
    "\n",
    "$\n",
    "\\mathbf{A} = \\begin{bmatrix} 3 & 1 & -2 \\\\ 5 & 4.3 & 6.1 \\\\ 2.9 & 1 & 2\\end{bmatrix}\n",
    "$\n",
    "\n",
    "### Non-Square Matrix\n",
    "\n",
    "Non-square matrices are a bit beyond the scope of this course, but we will touch on them a bit here. A common enounter of non-square matrices is in the form of data, where each row represents one record in a dataset. Below is a 5x3 matrix. \n",
    "\n",
    "$\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "3 & 9 & 0.5 \\\\\n",
    "7 & 2 & 13 \\\\\n",
    "14 & 6 & 0 \\\\\n",
    "4 & 0.1 & 5 \\\\\n",
    "11 & 9 & 7\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "From a geometric/visual interpretation, a non-square matrix means the transformation changes the dimensions of the space.\n",
    "\n",
    "### Identity Matrix \n",
    "\n",
    "When you encounter a matrix that is all 0's, except for a diagonal of 1's from the top-left to the bottom-right, we have what's called an identity matrix. It effectively identifies an undone transformation and the basis vectors are at their starting point. We will use the identity matrix later as our target for solving a system of equations. Applying an inverse matrix to a matrix will give us the identity matrix. \n",
    "\n",
    "$ \n",
    "\\mathbf{I} = \\begin{bmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$ \n",
    "\n",
    "### Diagonal Matrix\n",
    "\n",
    "Similar to the identity matrix is the diagonal matrix, which essentially are scaled basis vectors. These make them desirable for certain operations. Values only exist from the top-left to the bottom-right, and everything else are zeros. \n",
    "\n",
    "$ \n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "4 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 9\n",
    "\\end{bmatrix}\n",
    "$ \n",
    "\n",
    "### Triangular Matrix\n",
    "\n",
    "A triangular matrix is a matrix where the diagonal and everything above it (the top-right side) have values and everthig below is zero. \n",
    "\n",
    "$\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "1 & 3 & 2 \\\\\n",
    "0 & 2 & 7 \\\\\n",
    "0 & 0 & 5\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "The triangular matrix is useful for certain types of problems, like solving systems of equations and LU decomposition. \n",
    "\n",
    "### Sparse Matrix \n",
    "\n",
    "Occasionally, you might have a matrix that is mostly zeros and has very few non-zero values. These are sparse matrices, and are only interesting when it comes to computers and data memory. Instead of storing every value in the matrix, we can instead store only the non-zero values and their location in the matrix. This prevents redundnant storage of zeros. \n",
    "\n",
    "$ \n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "0 & 0 & 2 & 0 \\\\\n",
    "0 & 0 & 0 & 1 \\\\\n",
    "3 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "$ \n",
    "\n",
    "You will see the term sparse matrix used a lot in machine learning and computer science, as these areas commonly use sparse matrices to save on memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc242f6",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Is the matrix $ \\begin{bmatrix} 1 & 2 \\\\  0 & 0 \\end{bmatrix} $ linearly dependent? Why or why not?  \n",
    "\n",
    "Use Python and NumPy to calculate the answer, or calculate by hand on pencil and paper. \n",
    "\n",
    "### SCROLL DOWN FOR ANSWER\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "v "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b5d3c1",
   "metadata": {},
   "source": [
    "The linear transformation of this matrix has a determinant of zero, therefore it is linearly dependent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a276f912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from numpy.linalg import det \n",
    "\n",
    "i_hat = np.array([1,0])\n",
    "j_hat = np.array([2,0])\n",
    "\n",
    "A = np.array([i_hat,j_hat]).transpose()\n",
    "\n",
    "det(A)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
